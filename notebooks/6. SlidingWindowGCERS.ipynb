{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Counterfactual Explanation in Recommender Systems - Sliding Window Approach\n",
    "\n",
    "This notebook implements the sliding window approach for counterfactual explanations in group recommendations using the recoXplainer framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from recoxplainer.config import cfg\n",
    "from recoxplainer.data_reader import DataReader\n",
    "from recoxplainer.models import ALS\n",
    "from recoxplainer.recommender.grouprecommender import GroupRecommender\n",
    "from recoxplainer.evaluator.splitter import Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindow:\n",
    "    def __init__(self, arr, window_size):\n",
    "        self.arr = arr\n",
    "        self.window_size = window_size\n",
    "        self.index = 0\n",
    "\n",
    "    def get_next_window(self):\n",
    "        if self.index + self.window_size <= len(self.arr):\n",
    "            window = self.arr[self.index:self.index + self.window_size]\n",
    "            self.index += 1\n",
    "            return window\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeData(originalData, groupIds, itemIds):\n",
    "    newData = originalData.drop(\n",
    "        originalData[(originalData.itemId.isin(itemIds)) & originalData.userId.isin(groupIds)].index)\n",
    "    return newData\n",
    "\n",
    "def getGroupMembers(group):\n",
    "    group = group.strip()\n",
    "    members = group.split('_')\n",
    "    membersIds = []\n",
    "    for m in members:\n",
    "        membersIds.append(int(m))\n",
    "    return membersIds\n",
    "\n",
    "def getRatedItemsByAllGroupmembers(group, originalData):\n",
    "    movies = originalData[originalData.userId.isin(group)]['itemId'].unique()\n",
    "    return movies\n",
    "\n",
    "def getMoviesForRecommendation(originalData, movie_ids, group):\n",
    "    movie_ids_group = originalData.loc[originalData.userId.isin(group), \"itemId\"]\n",
    "    movie_ids_to_pred = np.setdiff1d(movie_ids, movie_ids_group)\n",
    "    return movie_ids_to_pred\n",
    "\n",
    "def findAverageItemIntensityExplanation(e, group, data):\n",
    "    explanationIntensity = []\n",
    "    groupint64 = [np.int64(g) for g in group]\n",
    "    \n",
    "    for item in e:\n",
    "        tmp = [item]\n",
    "        intensity = len(data[(data.itemId.isin(tmp) & data.userId.isin(groupint64))])\n",
    "        intensity = intensity / len(group)\n",
    "        explanationIntensity.append(intensity)\n",
    "    return explanationIntensity\n",
    "\n",
    "def findUserIntensity(e, group, data):\n",
    "    userIntensity = []\n",
    "    for mm in group:\n",
    "        m = np.int64(mm)\n",
    "        tmp = [m]\n",
    "        intensity = len(data[(data.itemId.isin(e) & (data.userId.isin(tmp)))])\n",
    "        intensity = intensity / len(e)\n",
    "        userIntensity.append(intensity)\n",
    "    return userIntensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuar\\miniconda3\\envs\\recoxplainer\\lib\\site-packages\\pandas\\core\\generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\Users\\usuar\\miniconda3\\envs\\recoxplainer\\lib\\site-packages\\pandas\\core\\generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data using recoXplainer\n",
    "data = DataReader(**cfg.data.ml100k)\n",
    "data.make_consecutive_ids_in_dataset()\n",
    "data.binarize(binary_threshold=1)\n",
    "\n",
    "# Split data\n",
    "sp = Splitter()\n",
    "train, test = sp.split_leave_n_out(data, frac=0.1)\n",
    "\n",
    "# Get movie IDs and groups\n",
    "movie_ids = data.dataset[\"itemId\"].unique()\n",
    "all_groups = data.read_groups('groupsWithHighRatings5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n",
      "c:\\Users\\usuar\\miniconda3\\envs\\recoxplainer\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train ALS model\n",
    "model = ALS(**cfg.model.als)\n",
    "model.fit(train)\n",
    "\n",
    "# Initialize group recommender\n",
    "group_recommender = GroupRecommender(train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing groups: 100%|██████████| 17/17 [01:05<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Main processing loop - direct adaptation of sliding-window.py logic\n",
    "results = []\n",
    "window_size = 3  # Start with small window for testing\n",
    "max_calls = 10000\n",
    "\n",
    "for group_str in tqdm(all_groups, desc=\"Processing groups\"):\n",
    "    # Get group members\n",
    "    group = getGroupMembers(group_str)\n",
    "    \n",
    "    # Get movies for recommendation\n",
    "    movies_to_recommend = getMoviesForRecommendation(train.dataset, movie_ids, group)\n",
    "    \n",
    "    if len(movies_to_recommend) == 0:\n",
    "        print(f\"No movies to recommend for group {group}\")\n",
    "        continue\n",
    "        \n",
    "    # Get initial recommendation\n",
    "    initial_rec = group_recommender.recommend_group_unseen_items(\n",
    "        group, movies_to_recommend, top_k=0\n",
    "    )\n",
    "    \n",
    "    # Get rated items\n",
    "    rated_items = getRatedItemsByAllGroupmembers(group, train.dataset)\n",
    "    \n",
    "    if len(rated_items) == 0:\n",
    "        print(f\"No rated items for group {group}\")\n",
    "        continue\n",
    "    \n",
    "    # Initialize sliding window\n",
    "    window = SlidingWindow(rated_items, window_size)\n",
    "    calls = 0\n",
    "    found_explanation = False\n",
    "    \n",
    "    while True:\n",
    "        if calls >= max_calls:\n",
    "            break\n",
    "            \n",
    "        current_window = window.get_next_window()\n",
    "        if current_window is None:\n",
    "            break\n",
    "            \n",
    "        # Try removing current window\n",
    "        modified_data = changeData(train.dataset, group, current_window)\n",
    "        calls += 1\n",
    "        \n",
    "        # Get new recommendation\n",
    "        new_rec = group_recommender.recommend_group_unseen_items(\n",
    "            group, movies_to_recommend, top_k=0\n",
    "        )\n",
    "        \n",
    "        if new_rec != initial_rec:\n",
    "            # Found a window that changes recommendation\n",
    "            # Try to find minimal subset\n",
    "            for length in range(1, len(current_window) + 1):\n",
    "                if found_explanation:\n",
    "                    break\n",
    "                    \n",
    "                for subset in itertools.combinations(current_window, length):\n",
    "                    if calls >= max_calls:\n",
    "                        break\n",
    "                        \n",
    "                    modified_data = changeData(train.dataset, group, list(subset))\n",
    "                    calls += 1\n",
    "                    \n",
    "                    new_rec = group_recommender.recommend_group_unseen_items(\n",
    "                        group, movies_to_recommend, top_k=0\n",
    "                    )\n",
    "                    \n",
    "                    if new_rec != initial_rec:\n",
    "                        # Found minimal explanation\n",
    "                        explanation = list(subset)\n",
    "                        \n",
    "                        # Calculate metrics\n",
    "                        item_intensity = findAverageItemIntensityExplanation(\n",
    "                            explanation, group, train.dataset)\n",
    "                        user_intensity = findUserIntensity(\n",
    "                            explanation, group, train.dataset)\n",
    "                        \n",
    "                        results.append({\n",
    "                            'group': group,\n",
    "                            'initial_rec': initial_rec,\n",
    "                            'new_rec': new_rec,\n",
    "                            'explanation': explanation,\n",
    "                            'explanation_size': len(explanation),\n",
    "                            'item_intensity': np.mean(item_intensity),\n",
    "                            'user_intensity': np.mean(user_intensity),\n",
    "                            'calls': calls\n",
    "                        })\n",
    "                        \n",
    "                        found_explanation = True\n",
    "                        break\n",
    "                        \n",
    "            if found_explanation:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "Number of groups processed: 17\n",
      "Number of successful explanations: 0\n",
      "Success rate: 0.00%\n",
      "\n",
      "No successful explanations were found.\n"
     ]
    }
   ],
   "source": [
    "# Analysis of results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Number of groups processed: {len(all_groups)}\")\n",
    "print(f\"Number of successful explanations: {len(results)}\")\n",
    "print(f\"Success rate: {len(results)/len(all_groups)*100:.2f}%\")\n",
    "\n",
    "if len(results) > 0:\n",
    "    print(\"\\nMetrics:\")\n",
    "    print(f\"Average explanation size: {results_df['explanation_size'].mean():.2f}\")\n",
    "    print(f\"Average item intensity: {results_df['item_intensity'].mean():.2f}\")\n",
    "    print(f\"Average user intensity: {results_df['user_intensity'].mean():.2f}\")\n",
    "    print(f\"Average number of calls: {results_df['calls'].mean():.2f}\")\n",
    "    \n",
    "    print(\"\\nDetailed Results:\")\n",
    "    display(results_df)\n",
    "else:\n",
    "    print(\"\\nNo successful explanations were found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoxplainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
