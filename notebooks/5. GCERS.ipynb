{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Counterfactual Explanation in Recommender Systems - Sliding Window Approach by Stratigi's (2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from recoxplainer.config import cfg\n",
    "from recoxplainer.data_reader.data_reader import DataReader\n",
    "from recoxplainer.models import ALS\n",
    "from recoxplainer.evaluator import Splitter, Evaluator\n",
    "from recoxplainer.recommender.grouprecommender import GroupRecommender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuar\\miniconda3\\envs\\recoxplainer\\lib\\site-packages\\pandas\\core\\generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\Users\\usuar\\miniconda3\\envs\\recoxplainer\\lib\\site-packages\\pandas\\core\\generic.py:5170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "data = DataReader(**cfg.data.ml100k)\n",
    "\n",
    "# Re-arrange users' and items' Ids\n",
    "data.make_consecutive_ids_in_dataset()\n",
    "\n",
    "# Because ALS works on implicit feedback we need to binarize it:+\n",
    "data.binarize(binary_threshold=1)\n",
    "\n",
    "# Prepare train and test sets:\n",
    "sp = Splitter()\n",
    "train, test = sp.split_leave_n_out(data, frac=0.1)\n",
    "\n",
    "# Prepare groups and movie IDs\n",
    "movie_ids = data.dataset[\"itemId\"].unique()\n",
    "all_groups = data.read_groups('groupsWithHighRatings5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing group: [522, 385, 234, 452, 594]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.29it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 10\n",
      "Processing group: [522, 385, 234, 246, 428]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.03it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 56\n",
      "Processing group: [452, 246, 220, 586, 82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.01it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 141\n",
      "Processing group: [452, 246, 220, 586, 198]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.78it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 30\n",
      "Processing group: [452, 246, 220, 586, 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.22it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 600\n",
      "Processing group: [220, 586, 73, 263, 372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.58it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 751\n",
      "Processing group: [220, 586, 73, 263, 365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.38it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 269\n",
      "Processing group: [220, 586, 73, 263, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.01it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 751\n",
      "Processing group: [73, 263, 563, 119, 66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.98it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 17\n",
      "Processing group: [73, 263, 563, 4, 312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.28it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 269\n",
      "Processing group: [73, 263, 563, 4, 354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.97it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 751\n",
      "Processing group: [14, 156, 45, 580, 560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.00it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 298\n",
      "Processing group: [14, 156, 45, 560, 318]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 12.52it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 306\n",
      "Processing group: [14, 156, 45, 560, 606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.38it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 960\n",
      "Processing group: [14, 156, 45, 89, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.81it/s]\n",
      " 10%|█         | 1/10 [00:00<00:00,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 83\n",
      "Processing group: [14, 156, 517, 462, 448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.06it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 239\n",
      "Processing group: [14, 156, 517, 89, 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: 364\n"
     ]
    }
   ],
   "source": [
    "# for group_id in all_groups:\n",
    "#     group_id = group_id.strip('\\n')\n",
    "#     members = data.parse_group_members(group_id)\n",
    "#     print(f\"Processing group: {members}\")\n",
    "    \n",
    "#     ## Get candidate movies for the recommendation - not seen by the group\n",
    "#     candidate_movies = data.get_items_for_group_recommendation(data.dataset, movie_ids, members)\n",
    "\n",
    "\n",
    "#     ## Train model\n",
    "#     als = ALS(**cfg.model.als)\n",
    "#     als.fit(train)\n",
    "\n",
    "#     # 4. Generate Recommendations\n",
    "#     recommender = Recommender(train, als)\n",
    "#     target_item = recommender.recommend_group(members, candidate_movies, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for group_id in all_groups:\n",
    "    group_id = group_id.strip('\\n')\n",
    "    members = data.parse_group_members(group_id)\n",
    "    print(f\"Processing group: {members}\")\n",
    "    \n",
    "    # Get candidate movies not seen by the group\n",
    "    candidate_movies = data.get_items_for_group_recommendation(\n",
    "        data.dataset, \n",
    "        movie_ids,\n",
    "        members\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    als = ALS(**cfg.model.als)\n",
    "    als.fit(train)\n",
    "\n",
    "    # Create recommender and get recommendations\n",
    "    recommender = GroupRecommender(train, als)\n",
    "    recommendations = recommender.recommend_group_unseen_items(\n",
    "        members, \n",
    "        candidate_movies.tolist(), \n",
    "        top_k=0  # Set to 0 for just the top item, or any positive integer for top-k\n",
    "    )\n",
    "\n",
    "    print(f\"Recommendations: {recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator\n",
    "# from typing import Dict, List, Union\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# class GroupRecommender(GenericRecommender):\n",
    "#     \"\"\"\n",
    "#     Extension of GenericRecommender to support group recommendations.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, dataset_metadata, model, top_n: int = 10):\n",
    "#         super(GroupRecommender, self).__init__(dataset_metadata, model, top_n)\n",
    "    \n",
    "#     def generate_recommendation(self, user_id: int, movie_ids_to_pred: List[int]) -> Dict[int, float]:\n",
    "#         \"\"\"\n",
    "#         Generate predictions for a single user for a list of items.\n",
    "#         This mirrors the original generate_recommendation function.\n",
    "        \n",
    "#         Args:\n",
    "#             user_id: User ID\n",
    "#             movie_ids_to_pred: List of movie IDs to predict ratings for\n",
    "            \n",
    "#         Returns:\n",
    "#             Dictionary mapping movie IDs to predicted ratings, sorted by prediction value\n",
    "#         \"\"\"\n",
    "#         # Get predictions from the model\n",
    "#         pred_ratings = self.model.predict(user_id, movie_ids_to_pred)\n",
    "        \n",
    "#         # Sort predictions in descending order\n",
    "#         index_max = (-pred_ratings).argsort()[:]\n",
    "        \n",
    "#         # Create dictionary with sorted predictions\n",
    "#         predictions = {}\n",
    "#         for i in index_max:\n",
    "#             predictions[movie_ids_to_pred[i]] = float(pred_ratings[i])\n",
    "        \n",
    "#         return predictions\n",
    "    \n",
    "#     def recommend_group(self, \n",
    "#                        members: List[int], \n",
    "#                        candidate_movies: List[int],\n",
    "#                        aggregation_method: str = \"average\") -> Dict[int, float]:\n",
    "#         \"\"\"\n",
    "#         Generate recommendations for a group of users.\n",
    "        \n",
    "#         Args:\n",
    "#             members: List of user IDs in the group\n",
    "#             candidate_movies: List of movie IDs not seen by any group member\n",
    "#             aggregation_method: Method to aggregate individual preferences\n",
    "            \n",
    "#         Returns:\n",
    "#             Dictionary mapping movie IDs to aggregated prediction scores\n",
    "#         \"\"\"\n",
    "#         # Get predictions for each group member\n",
    "#         predictions = {}\n",
    "#         for member in members:\n",
    "#             user_pred = self.generate_recommendation(member, candidate_movies)\n",
    "#             predictions[member] = user_pred\n",
    "        \n",
    "#         # Aggregate predictions\n",
    "#         return self._aggregate_predictions(predictions, len(members), aggregation_method)\n",
    "    \n",
    "#     def _aggregate_predictions(self, \n",
    "#                               predictions: Dict[int, Dict[int, float]], \n",
    "#                               group_size: int,\n",
    "#                               method: str = \"average\") -> Dict[int, float]:\n",
    "#         \"\"\"\n",
    "#         Aggregate predictions for a group.\n",
    "        \n",
    "#         Args:\n",
    "#             predictions: Dictionary mapping user IDs to their predictions\n",
    "#             group_size: Size of the group\n",
    "#             method: Aggregation method\n",
    "            \n",
    "#         Returns:\n",
    "#             Dictionary mapping item IDs to aggregated scores\n",
    "#         \"\"\"\n",
    "#         scores = {}\n",
    "        \n",
    "#         # Sum up scores for each item across all users\n",
    "#         for user, pred in predictions.items():\n",
    "#             for m in pred:\n",
    "#                 if m in scores:\n",
    "#                     scores[m] = scores[m] + pred[m]\n",
    "#                 else:\n",
    "#                     scores[m] = pred[m]\n",
    "        \n",
    "#         # Apply aggregation method\n",
    "#         if method == \"average\":\n",
    "#             # Average strategy (this matches your original code)\n",
    "#             group_pred = {}\n",
    "#             for m in scores:\n",
    "#                 group_pred[m] = scores[m] / group_size\n",
    "                \n",
    "#         elif method == \"least_misery\":\n",
    "#             # Least misery strategy\n",
    "#             group_pred = {}\n",
    "#             for m in scores.keys():\n",
    "#                 min_score = float('inf')\n",
    "#                 for user, preds in predictions.items():\n",
    "#                     if m in preds and preds[m] < min_score:\n",
    "#                         min_score = preds[m]\n",
    "#                 if min_score != float('inf'):\n",
    "#                     group_pred[m] = min_score\n",
    "                    \n",
    "#         elif method == \"most_pleasure\":\n",
    "#             # Most pleasure strategy\n",
    "#             group_pred = {}\n",
    "#             for m in scores.keys():\n",
    "#                 max_score = float('-inf')\n",
    "#                 for user, preds in predictions.items():\n",
    "#                     if m in preds and preds[m] > max_score:\n",
    "#                         max_score = preds[m]\n",
    "#                 if max_score != float('-inf'):\n",
    "#                     group_pred[m] = max_score\n",
    "#         else:\n",
    "#             # Default to average if method not recognized\n",
    "#             group_pred = {}\n",
    "#             for m in scores:\n",
    "#                 group_pred[m] = scores[m] / group_size\n",
    "        \n",
    "#         # Sort predictions (highest first)\n",
    "#         sorted_pred = dict(sorted(group_pred.items(), key=operator.itemgetter(1), reverse=True))\n",
    "        \n",
    "#         return sorted_pred\n",
    "    \n",
    "#     def recommend_group_unseen_items(self,\n",
    "#                                    group: List[int],\n",
    "#                                    item_ids: List[int],\n",
    "#                                    top_k: int = 0) -> Union[int, List[int]]:\n",
    "#         \"\"\"\n",
    "#         Generate recommendations of unseen items for a group.\n",
    "        \n",
    "#         Args:\n",
    "#             group: List of group member IDs\n",
    "#             item_ids: List of item IDs not seen by the group\n",
    "#             top_k: Number of recommendations to return (0 for just top-1, negative for all)\n",
    "            \n",
    "#         Returns:\n",
    "#             Single item ID or list of item IDs\n",
    "#         \"\"\"\n",
    "#         sorted_pred = self.recommend_group(group, item_ids)\n",
    "        \n",
    "#         if top_k == 0:\n",
    "#             # Return just the top item\n",
    "#             return next(iter(sorted_pred))\n",
    "#         elif top_k < 0:\n",
    "#             # Return all items\n",
    "#             return list(sorted_pred.keys())\n",
    "#         else:\n",
    "#             # Return top-k items\n",
    "#             list_rec = []\n",
    "#             i = 0\n",
    "#             for key in sorted_pred:\n",
    "#                 list_rec.append(key)\n",
    "#                 i = i + 1\n",
    "#                 if i == top_k:\n",
    "#                     break\n",
    "#             return list_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoxplainer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
